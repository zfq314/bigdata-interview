env {
     # You can set flink configuration here
     execution.parallelism = 1
     #execution.checkpoint.interval = 10000
     #execution.checkpoint.data-uri = "hdfs://hadoop102:9092/checkpoint"
   }

   # 在source所属的块中配置数据源
   source {
       KafkaTableStream {
           consumer.bootstrap.servers = "hadoop31:9092"
           consumer.group.id = "seatunnel-learn"
           topics = test_csv
           result_table_name = test
           format.type = csv
           schema = "[{\"field\":\"name\",\"type\":\"string\"},{\"field\":\"age\", \"type\": \"int\"}]"
           format.field-delimiter = ";"
           format.allow-comments = "true"
           format.ignore-parse-errors = "true"
       }
   }
   # 在transform的块中声明转换插件
   transform {

     sql {
       sql = "select name,age from test  where age > '"${age}"'"
     }
   }
   # 在sink块中声明要输出到哪
   sink {
      kafkaTable {
       topics = "test_sink"
       producer.bootstrap.servers = "hadoop31:9092"
           }
   }