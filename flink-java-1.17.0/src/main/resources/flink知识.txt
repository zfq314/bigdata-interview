Flink 依赖剖析

        Flink 发行版的 /lib 目录里还有包括常用模块在内的各种 JAR 文件，例如 执行 Table 作业的必需模块 、一组连接器和 format。默认情况下会自动加载，若要禁止加载只需将它们从 classpath 中的 /lib 目录中删除即可。
        Flink 还在 /opt 文件夹下提供了额外的可选依赖项，可以通过移动这些 JAR 文件到 /lib 目录来启用这些依赖项。

角色
     client(转换) jobmanage(管事) taskmanage(干活)

作业运行
         bin/flink run -m hadoop102:8081 -c com.zfq.wc.SocketStreamWordCount ./FlinkTutorial-1.0-SNAPSHOT.jar
         -m 指定jobmanager -c 指定入口类


部署模式
        会话模式
            单个规模小，执行时间短的作业，先开启会话，然后才提交作业，容易出现资源共享方面的问题
        单作业模式
            每个提交的作业开启一个集群，单作业模式，作业结束，集群关闭，资源释放，常采用的部署模式，需要借助其他的资源框架， yarn,kubernets(k8s)
        -- 应用代码在客户端执行，然后提交给Jobmanager ,需要占用大量的带宽，
        应用模式
            jobmanager只为了一个应用而存在，就是所谓的应用模式


        会话模式
        yarn部署模式
        YARN的会话模式与独立集群略有不同，需要首先申请一个YARN会话（YARN Session）来启动Flink集群。
        bin/yarn-session.sh -nm test
        bin/flink run -c com.zfq.wc.SocketStreamWordCount FlinkTutorial-1.0-SNAPSHOT.jar

        单作业模式部署
        在YARN环境中，由于有了外部平台做资源调度，所以我们也可以直接向YARN提交一个单独的作业，从而启动一个Flink集群。
        bin/flink run -d -t yarn-per-job -c com.zfq.wc.SocketStreamWordCount FlinkTutorial-1.0-SNAPSHOT.jar
        [zfq@hadoop102 flink-1.17.0]$ bin/flink list -t yarn-per-job -Dyarn.application.id=application_XXXX_YY
        [zfq@hadoop102 flink-1.17.0]$ bin/flink cancel -t yarn-per-job -Dyarn.application.id=application_XXXX_YY <jobId>

        应用模式部署
        应用模式同样非常简单，与单作业模式类似，直接执行flink run-application命令即可。
        [zfq@hadoop102 flink-1.17.0]$ bin/flink run-application -t yarn-application -c com.zfq.wc.SocketStreamWordCount FlinkTutorial-1.0-SNAPSHOT.jar
        （2）在命令行中查看或取消作业。
        [zfq@hadoop102 flink-1.17.0]$ bin/flink list -t yarn-application -Dyarn.application.id=application_XXXX_YY
        [zfq@hadoop102 flink-1.17.0]$ bin/flink cancel -t yarn-application -Dyarn.application.id=application_XXXX_YY <jobId>


        任务槽和并行度的关系
        任务槽和并行度都跟程序的并行执行有关，但两者是完全不同的概念。简单来说任务槽是静态的概念，是指TaskManager具有的并发执行能力，可以通过参数taskmanager.numberOfTaskSlots进行配置；而并行度是动态概念，也就是TaskManager运行程序时实际使用的并发能力，可以通过参数parallelism.default进行配置。
        举例说明：假设一共有3个TaskManager，每一个TaskManager中的slot数量设置为3个，那么一共有9个task slot，表示集群最多能并行执行9个同一算子的子任务。
        而我们定义word count程序的处理操作是四个转换算子：
        source→ flatmap→ reduce→ sink

        窗口
           按照驱动类型来分 时间窗口/计数窗口

           窗口分配数据的规则分类 滚动窗口/滑动窗口/会话窗口/全局窗口


           滚动窗口，每个时间段做聚合统计
           滑动窗口，计算频率更新高的场景
           会话窗口
           全局窗口

           按键窗口/非按键窗口

           窗口操作主要有2个部分，窗口分配器和窗口函数，窗口分配器指定指定窗口的类型，后面窗口函数作为一个参数，来定义窗口的具体逻辑

            定义窗口分配器（Window Assigners）是构建窗口算子的第一步，它的作用就是定义数据应该被“分配”到哪个窗口。所以可以说，窗口分配器其实就是在指定窗口的类型。
            窗口分配器最通用的定义方式，就是调用.window()方法。这个方法需要传入一个WindowAssigner作为参数，返回WindowedStream。
            如果是非按键分区窗口，那么直接调用.windowAll()方法，同样传入一个WindowAssigner，返回的是AllWindowedStream。

            时间窗口是最常用的窗口类型，又可以细分为滚动、滑动和会话三种。
            （1）滚动处理时间窗口
            窗口分配器由类TumblingProcessingTimeWindows提供，需要调用它的静态方法.of()。
            stream.keyBy(...)
                   .window(TumblingProcessingTimeWindows.of(Time.seconds(5)))
                   .aggregate(...)
            这里.of()方法需要传入一个Time类型的参数size，表示滚动窗口的大小，我们这里创建了一个长度为5秒的滚动窗口。
            另外，.of()还有一个重载方法，可以传入两个Time类型的参数：size和offset。第一个参数当然还是窗口大小，第二个参数则表示窗口起始点的偏移量。
            （2）滑动处理时间窗口
            窗口分配器由类SlidingProcessingTimeWindows提供，同样需要调用它的静态方法.of()。
            stream.keyBy(...)
                   .window(SlidingProcessingTimeWindows.of(Time.seconds(10)，Time.seconds(5)))
                   .aggregate(...)
            这里.of()方法需要传入两个Time类型的参数：size和slide，前者表示滑动窗口的大小，后者表示滑动窗口的滑动步长。我们这里创建了一个长度为10秒、滑动步长为5秒的滑动窗口。
            滑动窗口同样可以追加第三个参数，用于指定窗口起始点的偏移量，用法与滚动窗口完全一致。
            （3）处理时间会话窗口
            窗口分配器由类ProcessingTimeSessionWindows提供，需要调用它的静态方法.withGap()或者.withDynamicGap()。
            stream.keyBy(...)
                   .window(ProcessingTimeSessionWindows.withGap(Time.seconds(10)))
                   .aggregate(...)
            这里.withGap()方法需要传入一个Time类型的参数size，表示会话的超时时间，也就是最小间隔session gap。我们这里创建了静态会话超时时间为10秒的会话窗口。
            另外，还可以调用withDynamicGap()方法定义session gap的动态提取逻辑。
            （4）滚动事件时间窗口
            窗口分配器由类TumblingEventTimeWindows提供，用法与滚动处理事件窗口完全一致。
            stream.keyBy(...)
                   .window(TumblingEventTimeWindows.of(Time.seconds(5)))
                   .aggregate(...)
            （5）滑动事件时间窗口
            窗口分配器由类SlidingEventTimeWindows提供，用法与滑动处理事件窗口完全一致。
            stream.keyBy(...)
                   .window(SlidingEventTimeWindows.of(Time.seconds(10)，Time.seconds(5)))
                   .aggregate(...)
            （6）事件时间会话窗口
            窗口分配器由类EventTimeSessionWindows提供，用法与处理事件会话窗口完全一致。
            stream.keyBy(...)
                   .window(EventTimeSessionWindows.withGap(Time.seconds(10)))
                   .aggregate(...)


            计数窗口
            计数窗口概念非常简单，本身底层是基于全局窗口（Global Window）实现的。Flink为我们提供了非常方便的接口：直接调用.countWindow()方法。根据分配规则的不同，又可以分为滚动计数窗口和滑动计数窗口两类，下面我们就来看它们的具体实现。
            （1）滚动计数窗口
            滚动计数窗口只需要传入一个长整型的参数size，表示窗口的大小。
            stream.keyBy(...)
                   .countWindow(10)
            我们定义了一个长度为10的滚动计数窗口，当窗口中元素数量达到10的时候，就会触发计算执行并关闭窗口。
            （2）滑动计数窗口
            与滚动计数窗口类似，不过需要在.countWindow()调用时传入两个参数：size和slide，前者表示窗口大小，后者表示滑动步长。
            stream.keyBy(...)
                   .countWindow(10，3)
            我们定义了一个长度为10、滑动步长为3的滑动计数窗口。每个窗口统计10个数据，每隔3个数据就统计输出一次结果。
            3）全局窗口
            全局窗口是计数窗口的底层实现，一般在需要自定义窗口时使用。它的定义同样是直接调用.window()，分配器由GlobalWindows类提供。
            stream.keyBy(...)
                   .window(GlobalWindows.create());
            需要注意使用全局窗口，必须自行定义触发器才能实现窗口计算，否则起不到任何作用。

            窗口函数（WindowFunction）
            WindowFunction字面上就是“窗口函数”，它其实是老版本的通用窗口函数接口。我们可以基于WindowedStream调用.apply()方法，传入一个WindowFunction的实现类。
            stream
                .keyBy(<key selector>)
                .window(<window assigner>)
                .apply(new MyWindowFunction());
            这个类中可以获取到包含窗口所有数据的可迭代集合（Iterable），还可以拿到窗口（Window）本身的信息。
            不过WindowFunction能提供的上下文信息较少，也没有更高级的功能。事实上，它的作用可以被ProcessWindowFunction全覆盖，所以之后可能会逐渐弃用。


            处理窗口函数（ProcessWindowFunction）
            ProcessWindowFunction是Window API中最底层的通用窗口函数接口。之所以说它“最底层”，是因为除了可以拿到窗口中的所有数据之外，ProcessWindowFunction还可以获取到一个“上下文对象”（Context）。
            这个上下文对象非常强大，不仅能够获取窗口信息，还可以访问当前的时间和状态信息。这里的时间就包括了处理时间（processing time）和事件时间水位线（event time watermark）。
            这就使得ProcessWindowFunction更加灵活、功能更加丰富，其实就是一个增强版的WindowFunction。

            增量聚合和全窗口函数的结合使用
            在实际应用中，我们往往希望兼具这两者的优点，把它们结合在一起使用。Flink的Window API就给我们实现了这样的用法。
            我们之前在调用WindowedStream的.reduce()和.aggregate()方法时，只是简单地直接传入了一个ReduceFunction或AggregateFunction进行增量聚合。
            除此之外，其实还可以传入第二个参数：一个全窗口函数，可以是WindowFunction或者ProcessWindowFunction。
            // ReduceFunction与WindowFunction结合
            public <R> SingleOutputStreamOperator<R> reduce(
                    ReduceFunction<T> reduceFunction，WindowFunction<T，R，K，W> function)

            // ReduceFunction与ProcessWindowFunction结合
            public <R> SingleOutputStreamOperator<R> reduce(
                    ReduceFunction<T> reduceFunction，ProcessWindowFunction<T，R，K，W> function)

            // AggregateFunction与WindowFunction结合
            public <ACC，V，R> SingleOutputStreamOperator<R> aggregate(
                    AggregateFunction<T，ACC，V> aggFunction，WindowFunction<V，R，K，W> windowFunction)

            // AggregateFunction与ProcessWindowFunction结合
            public <ACC，V，R> SingleOutputStreamOperator<R> aggregate(
                    AggregateFunction<T，ACC，V> aggFunction,
                    ProcessWindowFunction<V，R，K，W> windowFunction)
            这样调用的处理机制是：基于第一个参数（增量聚合函数）来处理窗口数据，每来一个数据就做一次聚合；等到窗口需要触发计算时，则调用第二个参数（全窗口函数）的处理逻辑输出结果。
            需要注意的是，这里的全窗口函数就不再缓存所有数据了，而是直接将增量聚合函数的结果拿来当作了Iterable类型的输入。



        事件时间
        处理时间

        水位线

        在Flink中，用来衡量事件时间进展的标记，就被称作“水位线”（Watermark）。
        具体实现上，水位线可以看作一条特殊的数据记录，它是插入到数据流中的一个标记点，主要内容就是一个时间戳，用来指示当前的事件时间。
        而它插入流中的位置，就应该是在某个数据到来之后；这样就可以从这个数据中提取时间戳，作为当前水位线的时间戳了

        乱序数据处理

        生成水位线的总体原则
        完美的水位线是“绝对正确”的，也就是一个水位线一旦出现，就表示这个时间之前的数据已经全部到齐、之后再也不会出现了。不过如果要保证绝对正确，就必须等足够长的时间，这会带来更高的延迟。
        如果我们希望处理得更快、实时性更强，那么可以将水位线延迟设得低一些。
        这种情况下，可能很多迟到数据会在水位线之后才到达，就会导致窗口遗漏数据，计算结果不准确。
        当然，如果我们对准确性完全不考虑、一味地追求处理速度，可以直接使用处理时间语义，这在理论上可以得到最低的延迟。
        所以Flink中的水位线，其实是流处理中对低延迟和结果正确性的一个权衡机制，而且把控制的权力交给了程序员，我们可以在代码中定义水位线的生成策略。



        水位线生成策略
        在Flink的DataStream API中，有一个单独用于生成水位线的方法：.assignTimestampsAndWatermarks()，它主要用来为流中的数据分配时间戳，并生成水位线来指示事件时间。具体使用如下：
        DataStream<Event> stream = env.addSource(new ClickSource());

        DataStream<Event> withTimestampsAndWatermarks =
        stream.assignTimestampsAndWatermarks(<watermark strategy>);
        说明：WatermarkStrategy作为参数，这就是所谓的“水位线生成策略”。WatermarkStrategy是一个接口，该接口中包含了一个“时间戳分配器”TimestampAssigner和一个“水位线生成器”WatermarkGenerator。
        public interface WatermarkStrategy<T>
            extends TimestampAssignerSupplier<T>,
                    WatermarkGeneratorSupplier<T>{

            // 负责从流中数据元素的某个字段中提取时间戳，并分配给元素。时间戳的分配是生成水位线的基础。
            @Override
            TimestampAssigner<T> createTimestampAssigner(TimestampAssignerSupplier.Context context);

            // 主要负责按照既定的方式，基于时间戳生成水位线
            @Override
            WatermarkGenerator<T> createWatermarkGenerator(WatermarkGeneratorSupplier.Context context);
        }


        Flink内置水位线
        1）有序流中内置水位线设置
        对于有序流，主要特点就是时间戳单调增长，所以永远不会出现迟到数据的问题。这是周期性生成水位线的最简单的场景，直接调用WatermarkStrategy.forMonotonousTimestamps()方法就可以实现。


        乱序流中内置水位线设置
        由于乱序流中需要等待迟到数据到齐，所以必须设置一个固定量的延迟时间。这时生成水位线的时间戳，就是当前数据流中最大的时间戳减去延迟的结果，相当于把表调慢，当前时钟会滞后于数据的最大时间戳。
        调用WatermarkStrategy. forBoundedOutOfOrderness()方法就可以实现。这个方法需要传入一个maxOutOfOrderness参数，表示“最大乱序程度”，它表示数据流中乱序数据时间戳的最大差值；
        如果我们能确定乱序程度，那么设置对应时间长度的延迟，就可以等到所有的乱序数据了。